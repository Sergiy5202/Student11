{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретичний матеріал для підготовки до тесту з аналізу даних з використанням машинного навчання\n",
    "\n",
    "Цей матеріал охоплює основні концепції та методи машинного навчання, які допоможуть вам підготуватися до тесту, включаючи регресію, класифікацію, попередню обробку даних, оцінку моделей та інші важливі аспекти.\n",
    "\n",
    "---\n",
    "\n",
    "## Зміст\n",
    "\n",
    "1. **Вступ до машинного навчання**\n",
    "   - Що таке машинне навчання\n",
    "   - Типи машинного навчання\n",
    "2. **Регресія**\n",
    "   - Лінійна регресія\n",
    "   - Метрики оцінки моделей регресії\n",
    "3. **Класифікація**\n",
    "   - Логістична регресія\n",
    "   - Дерева рішень\n",
    "   - Метод найближчих сусідів (KNN)\n",
    "   - Random Forest\n",
    "   - Support Vector Machine (SVM)\n",
    "   - Метрики оцінки моделей класифікації\n",
    "4. **Перенавчання та недонавчання**\n",
    "   - Причини та способи запобігання\n",
    "5. **Попередня обробка даних**\n",
    "   - Очищення даних\n",
    "   - Обробка пропущених значень\n",
    "   - Перетворення змінних\n",
    "   - Масштабування даних\n",
    "   - Розділення даних на тренувальні та тестові набори\n",
    "6. **Гіперпараметри та їх підбір**\n",
    "   - Що таке гіперпараметри\n",
    "   - GridSearchCV та RandomizedSearchCV\n",
    "7. **Крос-валідація**\n",
    "   - Принципи та переваги\n",
    "8. **Регуляризація**\n",
    "   - Метод L1 та L2 регуляризації\n",
    "9. **Зниження розмірності**\n",
    "   - Principal Component Analysis (PCA)\n",
    "10. **Ансамблеві методи**\n",
    "    - Random Forest\n",
    "    - Gradient Boosting\n",
    "11. **Вибір та оцінка моделей**\n",
    "    - Критерії вибору моделей\n",
    "    - Метрики оцінки\n",
    "12. **Практичні аспекти**\n",
    "    - Робота з великими наборами даних\n",
    "    - Бібліотеки Python для машинного навчання\n",
    "    - Виявлення та обробка мультиколінеарності\n",
    "13. **Додаткові концепції**\n",
    "    - Confusion Matrix\n",
    "    - ROC та AUC\n",
    "    - Learning Curves\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Вступ до машинного навчання\n",
    "\n",
    "### Що таке машинне навчання\n",
    "\n",
    "**Машинне навчання** — це підгалузь штучного інтелекту, яка займається розробкою алгоритмів та моделей, що дозволяють комп'ютерам навчатися на основі даних без явного програмування.\n",
    "\n",
    "### Типи машинного навчання\n",
    "\n",
    "- **Навчання з учителем (Supervised Learning)**: Моделі навчаються на мічених даних, де кожен приклад має вхідні дані та відповідний цільовий вихід.\n",
    "\n",
    "  - **Регресія**: Передбачення неперервних числових значень (наприклад, передбачення ціни будинку).\n",
    "  - **Класифікація**: Присвоєння вхідним даним однієї з дискретних категорій (наприклад, спам/не спам).\n",
    "\n",
    "- **Навчання без учителя (Unsupervised Learning)**: Моделі працюють з неміченими даними та шукають схеми або структури в даних.\n",
    "\n",
    "  - **Кластеризація**: Групування схожих даних (наприклад, сегментація клієнтів).\n",
    "  - **Зниження розмірності**: Спрощення складних даних (наприклад, PCA).\n",
    "\n",
    "- **Навчання з підкріпленням (Reinforcement Learning)**: Агент навчається шляхом взаємодії з середовищем та отримання винагород або штрафів.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Регресія\n",
    "\n",
    "### Лінійна регресія\n",
    "\n",
    "**Лінійна регресія** — це метод для моделювання залежності між однією або кількома незалежними змінними та залежною змінною шляхом підбору лінійного рівняння до спостережуваних даних.\n",
    "\n",
    "**Модель лінійної регресії**:\n",
    "\n",
    "\\[\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_n x_n + \\epsilon\n",
    "\\]\n",
    "\n",
    "- \\( y \\) — цільова змінна.\n",
    "- \\( x_i \\) — незалежні змінні.\n",
    "- \\( \\beta_i \\) — коефіцієнти моделі.\n",
    "- \\( \\epsilon \\) — похибка.\n",
    "\n",
    "### Метрики оцінки моделей регресії\n",
    "\n",
    "- **Mean Squared Error (MSE)**: Середнє значення квадратів різниць між реальними та передбаченими значеннями.\n",
    "\n",
    "  \\[\n",
    "  MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "  \\]\n",
    "\n",
    "- **Root Mean Squared Error (RMSE)**: Квадратний корінь з MSE.\n",
    "\n",
    "  \\[\n",
    "  RMSE = \\sqrt{MSE}\n",
    "  \\]\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: Середнє значення абсолютних різниць між реальними та передбаченими значеннями.\n",
    "\n",
    "  \\[\n",
    "  MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|\n",
    "  \\]\n",
    "\n",
    "- **Коефіцієнт детермінації (R²)**: Відображає, яка частка варіації залежної змінної пояснюється моделлю.\n",
    "\n",
    "  \\[\n",
    "  R^2 = 1 - \\frac{\\sum (y_i - \\hat{y}_i)^2}{\\sum (y_i - \\bar{y})^2}\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Класифікація\n",
    "\n",
    "### Логістична регресія\n",
    "\n",
    "**Логістична регресія** використовується для задач бінарної класифікації. Модель передбачає ймовірність належності до певного класу.\n",
    "\n",
    "**Сигмоїдна функція**:\n",
    "\n",
    "\\[\n",
    "P(y=1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x_1 + \\dots + \\beta_n x_n)}}\n",
    "\\]\n",
    "\n",
    "### Дерева рішень\n",
    "\n",
    "**Дерева рішень** використовують структуру дерева для прийняття рішень, розбиваючи дані на підмножини на основі значень ознак.\n",
    "\n",
    "### Метод найближчих сусідів (KNN)\n",
    "\n",
    "**KNN** класифікує нові точки даних на основі найближчих \\( k \\) сусідів у навчальному наборі.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "**Random Forest** — ансамблевий метод, що використовує велику кількість дерев рішень та об'єднує їх результати для покращення точності та зниження перенавчання.\n",
    "\n",
    "### Support Vector Machine (SVM)\n",
    "\n",
    "**SVM** шукає гіперплощину, яка максимально розділяє класи, використовуючи точки, найближчі до межі (підтримуючі вектори).\n",
    "\n",
    "### Метрики оцінки моделей класифікації\n",
    "\n",
    "- **Accuracy (Точність)**: Частка правильних передбачень.\n",
    "\n",
    "  \\[\n",
    "  Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "  \\]\n",
    "\n",
    "- **Precision (Прецизійність)**: Частка правильних позитивних передбачень серед всіх передбачених позитивних.\n",
    "\n",
    "  \\[\n",
    "  Precision = \\frac{TP}{TP + FP}\n",
    "  \\]\n",
    "\n",
    "- **Recall (Повнота)**: Частка правильно передбачених позитивних випадків серед всіх реальних позитивних.\n",
    "\n",
    "  \\[\n",
    "  Recall = \\frac{TP}{TP + FN}\n",
    "  \\]\n",
    "\n",
    "- **F1-Score**: Гармонійне середнє між Precision та Recall.\n",
    "\n",
    "  \\[\n",
    "  F1 = 2 \\times \\frac{Precision \\times Recall}{Precision + Recall}\n",
    "  \\]\n",
    "\n",
    "- **ROC-AUC**: Площа під кривою ROC, що відображає співвідношення між TPR (True Positive Rate) та FPR (False Positive Rate).\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Перенавчання та недонавчання\n",
    "\n",
    "### Перенавчання (Overfitting)\n",
    "\n",
    "Модель добре працює на тренувальних даних, але погано на нових, через те, що вона \"вивчила\" шум та випадкові коливання.\n",
    "\n",
    "**Способи запобігання**:\n",
    "\n",
    "- **Крос-валідація**\n",
    "- **Регуляризація** (L1, L2)\n",
    "- **Зменшення складності моделі**\n",
    "- **Збільшення розміру тренувального набору**\n",
    "\n",
    "### Недонавчання (Underfitting)\n",
    "\n",
    "Модель не здатна вловити основні закономірності в даних, погано працює як на тренувальних, так і на тестових даних.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Попередня обробка даних\n",
    "\n",
    "### Очищення даних\n",
    "\n",
    "- Видалення або корекція некоректних значень.\n",
    "- Видалення дублікатів.\n",
    "\n",
    "### Обробка пропущених значень\n",
    "\n",
    "- **Видалення рядків** з пропущеними значеннями.\n",
    "- **Заповнення середнім** (для числових змінних).\n",
    "- **Заповнення медіаною** або **модою**.\n",
    "- **Передбачення пропущених значень** за допомогою моделей.\n",
    "\n",
    "### Перетворення змінних\n",
    "\n",
    "- **Label Encoding**: Перетворення категоріальних змінних на числові шляхом присвоєння унікальних чисел.\n",
    "- **One-Hot Encoding**: Створення нових бінарних стовпців для кожного унікального значення категоріальної змінної.\n",
    "\n",
    "### Масштабування даних\n",
    "\n",
    "- **Min-Max Scaling**: Приведення даних до діапазону [0,1].\n",
    "\n",
    "  \\[\n",
    "  X_{scaled} = \\frac{X - X_{min}}{X_{max} - X_{min}}\n",
    "  \\]\n",
    "\n",
    "- **Standardization**: Приведення даних до середнього 0 та стандартного відхилення 1.\n",
    "\n",
    "  \\[\n",
    "  X_{scaled} = \\frac{X - \\mu}{\\sigma}\n",
    "  \\]\n",
    "\n",
    "### Розділення даних на тренувальні та тестові набори\n",
    "\n",
    "- Використовується функція `train_test_split` з бібліотеки sklearn.\n",
    "- **test_size**: Відсоток даних, що виділяється на тестовий набір (наприклад, 0.2 для 20%).\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Гіперпараметри та їх підбір\n",
    "\n",
    "### Що таке гіперпараметри\n",
    "\n",
    "- Параметри, які задаються перед навчанням моделі та не оновлюються під час навчання.\n",
    "- Впливають на продуктивність моделі (наприклад, глибина дерева рішень, кількість сусідів у KNN).\n",
    "\n",
    "### GridSearchCV та RandomizedSearchCV\n",
    "\n",
    "- **GridSearchCV**: Перебирає всі комбінації заданих гіперпараметрів для пошуку найкращих.\n",
    "- **RandomizedSearchCV**: Випадково вибирає комбінації гіперпараметрів, що зменшує час пошуку.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Крос-валідація\n",
    "\n",
    "- **Крос-валідація**: Метод оцінки моделі шляхом розбиття даних на кілька частин (фолдів) та тренування/тестування на різних підмножинах.\n",
    "- **K-Fold Cross-Validation**: Дані діляться на K частин; модель тренується на K-1 частинах та тестується на одній, процес повторюється K разів.\n",
    "\n",
    "**Переваги**:\n",
    "\n",
    "- Зменшує варіативність оцінки моделі.\n",
    "- Використовує всі дані як для тренування, так і для тестування.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Регуляризація\n",
    "\n",
    "- **Регуляризація**: Метод запобігання перенавчанню шляхом додавання штрафу за складність моделі.\n",
    "\n",
    "### Типи регуляризації\n",
    "\n",
    "- **L1 Регуляризація (Lasso Regression)**:\n",
    "\n",
    "  Додає до функції втрат суму абсолютних значень коефіцієнтів.\n",
    "\n",
    "- **L2 Регуляризація (Ridge Regression)**:\n",
    "\n",
    "  Додає до функції втрат суму квадратів коефіцієнтів.\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Зниження розмірності\n",
    "\n",
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "- **PCA**: Метод для зниження розмірності даних шляхом перетворення до нового набору змінних (головних компонент), які є ортогональними та пояснюють максимальну варіацію в даних.\n",
    "\n",
    "**Переваги**:\n",
    "\n",
    "- Зменшує розмірність, що спрощує модель.\n",
    "- Видаляє корельовані змінні.\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Ансамблеві методи\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "- Використовує велику кількість дерев рішень та об'єднує їх результати.\n",
    "- Знижує варіативність та покращує точність.\n",
    "\n",
    "### Gradient Boosting\n",
    "\n",
    "- Послідовно тренує моделі, кожна з яких намагається виправити помилки попередньої.\n",
    "- Ефективний для складних задач, але може бути схильний до перенавчання.\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Вибір та оцінка моделей\n",
    "\n",
    "### Критерії вибору моделей\n",
    "\n",
    "- **Продуктивність** на тренувальних та тестових даних.\n",
    "- **Складність** моделі.\n",
    "- **Інтерпретованість** результатів.\n",
    "- **Час та ресурси**, необхідні для тренування.\n",
    "\n",
    "### Метрики оцінки\n",
    "\n",
    "- Залежить від задачі (регресія чи класифікація).\n",
    "- Враховуйте особливості даних (наприклад, незбалансованість класів).\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Практичні аспекти\n",
    "\n",
    "### Робота з великими наборами даних\n",
    "\n",
    "**Проблеми**:\n",
    "\n",
    "- **Довгий час навчання**.\n",
    "- **Велике споживання пам'яті**.\n",
    "- **Труднощі з візуалізацією**.\n",
    "\n",
    "**Рішення**:\n",
    "\n",
    "- Використання більш ефективних алгоритмів.\n",
    "- Застосування методів вибірки або агрегації.\n",
    "- Розподілені обчислення.\n",
    "\n",
    "### Бібліотеки Python для машинного навчання\n",
    "\n",
    "- **scikit-learn**: Основна бібліотека для класичних алгоритмів машинного навчання.\n",
    "- **NumPy**: Робота з багатовимірними масивами.\n",
    "- **Pandas**: Маніпуляція з табличними даними.\n",
    "- **Matplotlib** та **Seaborn**: Візуалізація даних.\n",
    "\n",
    "### Виявлення та обробка мультиколінеарності\n",
    "\n",
    "- **Мультиколінеарність**: Кореляція між незалежними змінними.\n",
    "- **Виявлення**: Використання **кореляційної матриці**.\n",
    "- **Обробка**: Видалення або об'єднання корельованих змінних, використання PCA.\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Додаткові концепції\n",
    "\n",
    "### Confusion Matrix (Матриця неточностей)\n",
    "\n",
    "- **Структура**:\n",
    "\n",
    "  |           | Передбачено позитив | Передбачено негатив |\n",
    "  |-----------|---------------------|---------------------|\n",
    "  | **Реально позитив** | True Positive (TP)    | False Negative (FN)  |\n",
    "  | **Реально негатив** | False Positive (FP)   | True Negative (TN)   |\n",
    "\n",
    "- Дозволяє детально оцінити якість класифікації.\n",
    "\n",
    "### ROC та AUC\n",
    "\n",
    "- **ROC-крива**: Графік залежності TPR від FPR при різних порогах класифікації.\n",
    "- **AUC (Area Under Curve)**: Площа під ROC-кривою; чим ближче до 1, тим краща модель.\n",
    "\n",
    "### Learning Curves (Криві навчання)\n",
    "\n",
    "- Графік залежності продуктивності моделі від розміру тренувального набору.\n",
    "- Дозволяє виявити перенавчання або недонавчання.\n",
    "\n",
    "---\n",
    "\n",
    "## Підсумки\n",
    "\n",
    "- **Регресія** використовується для передбачення неперервних значень, **класифікація** — для категорій.\n",
    "- Важливо правильно **попередньо обробити дані**, включаючи очищення, масштабування та кодування.\n",
    "- **Перенавчання** можна запобігти за допомогою регуляризації, крос-валідації та інших методів.\n",
    "- **Оцінка моделей** повинна проводитися з використанням відповідних метрик.\n",
    "- **Гіперпараметри** впливають на продуктивність моделі та можуть бути оптимізовані.\n",
    "- Використання **бібліотек Python** спрощує процес моделювання та аналізу даних.\n",
    "\n",
    "---\n",
    "\n",
    "**Рекомендації для подальшого вивчення**:\n",
    "\n",
    "- Практикуйтеся з реальними наборами даних.\n",
    "- Ознайомтеся з документацією бібліотек, таких як scikit-learn.\n",
    "- Вивчайте додаткові алгоритми та методи, такі як нейронні мережі."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
